{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aaOUuqA0G58",
        "outputId": "c83bad09-8d6e-4a3b-da6b-a5fb5ceb4738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4553 - loss: 2.0520 - val_accuracy: 0.7828 - val_loss: 0.7921\n",
            "Epoch 2/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.7183 - val_accuracy: 0.8365 - val_loss: 0.5616\n",
            "Epoch 3/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.5289 - val_accuracy: 0.8685 - val_loss: 0.4484\n",
            "Epoch 4/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.3984 - val_accuracy: 0.8842 - val_loss: 0.3826\n",
            "Epoch 5/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.3429 - val_accuracy: 0.9013 - val_loss: 0.3306\n",
            "Epoch 6/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2839 - val_accuracy: 0.9155 - val_loss: 0.2881\n",
            "Epoch 7/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2455 - val_accuracy: 0.9208 - val_loss: 0.2570\n",
            "Epoch 8/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.2167 - val_accuracy: 0.9243 - val_loss: 0.2463\n",
            "Epoch 9/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1930 - val_accuracy: 0.9312 - val_loss: 0.2232\n",
            "Epoch 10/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1839 - val_accuracy: 0.9330 - val_loss: 0.2060\n",
            "Epoch 11/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1559 - val_accuracy: 0.9375 - val_loss: 0.1993\n",
            "Epoch 12/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1439 - val_accuracy: 0.9380 - val_loss: 0.1866\n",
            "Epoch 13/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1342 - val_accuracy: 0.9405 - val_loss: 0.1825\n",
            "Epoch 14/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1259 - val_accuracy: 0.9377 - val_loss: 0.1784\n",
            "Epoch 15/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.1160 - val_accuracy: 0.9392 - val_loss: 0.1813\n",
            "Epoch 16/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1091 - val_accuracy: 0.9467 - val_loss: 0.1636\n",
            "Epoch 17/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1021 - val_accuracy: 0.9475 - val_loss: 0.1580\n",
            "Epoch 18/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0969 - val_accuracy: 0.9455 - val_loss: 0.1659\n",
            "Epoch 19/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0844 - val_accuracy: 0.9503 - val_loss: 0.1575\n",
            "Epoch 20/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0819 - val_accuracy: 0.9517 - val_loss: 0.1477\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Model Accuracy: 0.9517\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       149\n",
            "           1       0.94      0.92      0.93       153\n",
            "           2       0.96      0.95      0.96       137\n",
            "           3       0.91      0.97      0.94       156\n",
            "           4       0.96      0.95      0.95       141\n",
            "           5       0.92      0.95      0.94       140\n",
            "           6       0.95      0.91      0.93       160\n",
            "           7       0.86      0.92      0.89       144\n",
            "           8       0.98      0.90      0.94       146\n",
            "           9       0.90      0.97      0.93       149\n",
            "          10       0.87      0.92      0.89       130\n",
            "          11       0.95      0.96      0.96       155\n",
            "          12       0.96      0.99      0.98       168\n",
            "          13       0.99      0.94      0.96       151\n",
            "          14       0.95      0.95      0.95       145\n",
            "          15       0.96      0.97      0.96       173\n",
            "          16       0.98      0.96      0.97       166\n",
            "          17       0.95      0.86      0.90       160\n",
            "          18       0.95      0.99      0.97       171\n",
            "          19       0.99      0.94      0.96       163\n",
            "          20       0.96      0.97      0.96       183\n",
            "          21       0.96      0.97      0.97       158\n",
            "          22       0.99      0.99      0.99       148\n",
            "          23       0.97      0.98      0.97       154\n",
            "          24       0.97      0.97      0.97       168\n",
            "          25       0.99      0.97      0.98       132\n",
            "\n",
            "    accuracy                           0.95      4000\n",
            "   macro avg       0.95      0.95      0.95      4000\n",
            "weighted avg       0.95      0.95      0.95      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/Alphabets_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "df['letter'] = label_encoder.fit_transform(df['letter'])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['letter'])\n",
        "y = df['letter']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build ANN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    }
  ]
}